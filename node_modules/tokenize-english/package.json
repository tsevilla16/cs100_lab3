{
  "_from": "tokenize-english@^1.0.3",
  "_id": "tokenize-english@1.0.3",
  "_inBundle": false,
  "_integrity": "sha1-tBxrp13HcCEXgEgT9cCmDu1gc6I=",
  "_location": "/tokenize-english",
  "_phantomChildren": {},
  "_requested": {
    "type": "range",
    "registry": true,
    "raw": "tokenize-english@^1.0.3",
    "name": "tokenize-english",
    "escapedName": "tokenize-english",
    "rawSpec": "^1.0.3",
    "saveSpec": null,
    "fetchSpec": "^1.0.3"
  },
  "_requiredBy": [
    "#USER",
    "/"
  ],
  "_resolved": "https://registry.npmjs.org/tokenize-english/-/tokenize-english-1.0.3.tgz",
  "_shasum": "b41c6ba75dc7702117804813f5c0a60eed6073a2",
  "_spec": "tokenize-english@^1.0.3",
  "_where": "/Users/jcrogoff/Desktop/CS100Lab3/lab3",
  "author": {
    "name": "GitBook",
    "email": "contact@gitbook.com"
  },
  "bugs": {
    "url": "https://github.com/GitbookIO/tokenize-english/issues"
  },
  "bundleDependencies": false,
  "dependencies": {
    "lodash": "^3.2.0"
  },
  "deprecated": false,
  "description": "Tokenizer for english sentences",
  "devDependencies": {
    "mocha": "2.3.3",
    "should": "7.1.0",
    "tokenize-htmltext": "1.0.0",
    "tokenize-text": "1.1.2"
  },
  "homepage": "https://github.com/GitbookIO/tokenize-english",
  "license": "Apache-2.0",
  "main": "lib/index.js",
  "name": "tokenize-english",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/GitbookIO/tokenize-english.git"
  },
  "scripts": {
    "test": "mocha --reporter spec --recursive --bail"
  },
  "version": "1.0.3"
}
